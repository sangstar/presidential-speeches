{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sangersteel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/presidential-speeches.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_allcaps_in_list(doc):\n",
    "    tokens = doc.split(\" \")\n",
    "    for token in tokens:\n",
    "        if token.upper() == token and token != \"PRESIDENT\" and \"(\" not in token:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warren G. Harding\n",
      "Lyndon B. Johnson\n",
      "John F. Kennedy\n",
      "Benjamin Harrison\n",
      "Franklin D. Roosevelt\n",
      "Harry S. Truman\n",
      "Richard M. Nixon\n",
      "Dwight D. Eisenhower\n",
      "Ronald Reagan\n",
      "Andrew Johnson\n",
      "Gerald Ford\n",
      "Jimmy Carter\n",
      "George H. W. Bush\n",
      "Bill Clinton\n",
      "George W. Bush\n",
      "Barack Obama\n",
      "George Washington\n",
      "John Adams\n",
      "Thomas Jefferson\n",
      "Abraham Lincoln\n",
      "James Madison\n",
      "James Monroe\n",
      "John Quincy Adams\n",
      "Andrew Jackson\n",
      "Martin Van Buren\n",
      "William Harrison\n",
      "John Tyler\n",
      "James K. Polk\n",
      "Zachary Taylor\n",
      "Millard Fillmore\n",
      "Franklin Pierce\n",
      "James Buchanan\n",
      "Ulysses S. Grant\n",
      "Rutherford B. Hayes\n",
      "James A. Garfield\n",
      "Chester A. Arthur\n",
      "Grover Cleveland\n",
      "William McKinley\n",
      "Theodore Roosevelt\n",
      "William Taft\n",
      "Woodrow Wilson\n",
      "Calvin Coolidge\n",
      "Herbert Hoover\n",
      "Donald Trump\n",
      "Joe Biden\n"
     ]
    }
   ],
   "source": [
    "pres = {}\n",
    "for index, row in df.iterrows():\n",
    "    president = row['president']\n",
    "    if president not in pres:\n",
    "        pres[president] = ''\n",
    "    else:\n",
    "        pres[president] += row['transcript'].replace(\"\\n\",\"\").replace(\"\\r\",\"\") + \"[NEXT]\"\n",
    "\n",
    "\n",
    "for keys in pres.keys():\n",
    "    print(keys)\n",
    "    sentences = [nltk.sent_tokenize(x) for x in pres[keys].split(\"[NEXT]\")]\n",
    "    sentences = [item for sublist in sentences for item in sublist if not check_if_allcaps_in_list(item)]\n",
    "    random.shuffle(sentences)\n",
    "    pres[keys] = sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune BERT model for this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(df['president']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for key in pres:\n",
    "    current = pres[key]\n",
    "    for sent in current:\n",
    "            cleaned_sent = \" \".join([x for x in sent.split(\" \") if \"(\" not in x and \")\" not in x and \"[\" not in x and \"]\" not in x])\n",
    "            vals.append([sent, key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(data = vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.columns = ['text','out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donald Trump             8628\n",
       "Barack Obama             7353\n",
       "Ronald Reagan            5740\n",
       "Lyndon B. Johnson        3864\n",
       "Bill Clinton             3763\n",
       "Theodore Roosevelt       3740\n",
       "George W. Bush           3628\n",
       "John F. Kennedy          3271\n",
       "George H. W. Bush        3035\n",
       "Abraham Lincoln          2301\n",
       "Andrew Jackson           2252\n",
       "Franklin D. Roosevelt    2235\n",
       "Joe Biden                2135\n",
       "Calvin Coolidge          2033\n",
       "Benjamin Harrison        1749\n",
       "Jimmy Carter             1727\n",
       "Woodrow Wilson           1618\n",
       "Herbert Hoover           1614\n",
       "James K. Polk            1471\n",
       "Grover Cleveland         1465\n",
       "James Buchanan           1461\n",
       "Andrew Johnson           1445\n",
       "William Taft             1368\n",
       "William McKinley         1241\n",
       "Ulysses S. Grant         1179\n",
       "John Tyler                896\n",
       "Martin Van Buren          888\n",
       "James Monroe              876\n",
       "Rutherford B. Hayes       870\n",
       "Harry S. Truman           794\n",
       "Warren G. Harding         793\n",
       "Gerald Ford               735\n",
       "Franklin Pierce           731\n",
       "Richard M. Nixon          667\n",
       "John Quincy Adams         469\n",
       "James Madison             409\n",
       "Millard Fillmore          371\n",
       "Chester A. Arthur         354\n",
       "Dwight D. Eisenhower      272\n",
       "John Adams                220\n",
       "George Washington         219\n",
       "Thomas Jefferson          130\n",
       "Zachary Taylor            116\n",
       "Name: out, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['out'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat = pd.get_dummies(dat, columns = ['out'], prefix_sep = '', prefix = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dat['text']\n",
    "y = dat['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataframe into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, shuffle=True,stratify=y)\n",
    "\n",
    "# Split the train set into a train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True,stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on Sangers-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:128\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mdeclare_hyperparameters(hp)\n\u001b[1;32m    129\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[39m# Lists of stacks of conditions used during `explore_space()`.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:114\u001b[0m, in \u001b[0;36mHyperModel.declare_hyperparameters\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeclare_hyperparameters\u001b[39m(\u001b[39mself\u001b[39m, hp):\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:4199\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 4199\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op_def_cache[\u001b[39mtype\u001b[39;49m]\n\u001b[1;32m   4200\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CaseFoldUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:958\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 958\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[1;32m    959\u001b[0m                   ckpt_options, options, filters)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:154\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 154\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[1;32m    155\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[1;32m    156\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[1;32m    157\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[1;32m    158\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m# captures.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/saved_model/function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m--> 416\u001b[0m   func_graph \u001b[39m=\u001b[39m function_def_lib\u001b[39m.\u001b[39;49mfunction_def_to_graph(\n\u001b[1;32m    417\u001b[0m       fdef,\n\u001b[1;32m    418\u001b[0m       structured_input_signature\u001b[39m=\u001b[39;49mstructured_input_signature,\n\u001b[1;32m    419\u001b[0m       structured_outputs\u001b[39m=\u001b[39;49mstructured_outputs)\n\u001b[1;32m    420\u001b[0m \u001b[39m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m# custom gradients)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/framework/function_def_to_graph.py:82\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[1;32m     80\u001b[0m         input_shapes\u001b[39m.\u001b[39mappend(input_shape)\n\u001b[0;32m---> 82\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[39m=\u001b[39m function_def_to_graph_def(\n\u001b[1;32m     83\u001b[0m     fdef, input_shapes)\n\u001b[1;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m     86\u001b[0m   \u001b[39m# Add all function nodes to the graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/framework/function_def_to_graph.py:252\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m   op_def \u001b[39m=\u001b[39m default_graph\u001b[39m.\u001b[39;49m_get_op_def(node_def\u001b[39m.\u001b[39;49mop)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m op_def\u001b[39m.\u001b[39mattr:\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:4203\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   4202\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[0;32m-> 4203\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphGetOpDef(c_graph, compat\u001b[39m.\u001b[39;49mas_bytes(\u001b[39mtype\u001b[39;49m),\n\u001b[1;32m   4204\u001b[0m                                      buf)\n\u001b[1;32m   4205\u001b[0m data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on Sangers-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[39m=\u001b[39m (X_train, y_train)\n\u001b[1;32m      2\u001b[0m val \u001b[39m=\u001b[39m (X_val, y_val)\n\u001b[0;32m----> 3\u001b[0m BERT\u001b[39m.\u001b[39;49mget_best_model(train, val, epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, patience \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, overwrite \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, num_models \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 238\u001b[0m, in \u001b[0;36mBERTmodel.get_best_model\u001b[0;34m(self, train, val, epochs, patience, overwrite, num_models)\u001b[0m\n\u001b[1;32m    236\u001b[0m X_train, y_train \u001b[39m=\u001b[39m train\n\u001b[1;32m    237\u001b[0m X_val, y_val \u001b[39m=\u001b[39m val\n\u001b[0;32m--> 238\u001b[0m tuner \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_tuner(overwrite)\n\u001b[1;32m    239\u001b[0m tuner\u001b[39m.\u001b[39msearch(X_train, y_train,\n\u001b[1;32m    240\u001b[0m      validation_data\u001b[39m=\u001b[39m(X_val, y_val),\n\u001b[1;32m    241\u001b[0m      epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m,\n\u001b[1;32m    242\u001b[0m      callbacks\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)])\n\u001b[1;32m    243\u001b[0m best_hps \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters()\n",
      "Cell \u001b[0;32mIn[8], line 225\u001b[0m, in \u001b[0;36mBERTmodel.initialize_tuner\u001b[0;34m(self, overwrite)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_tuner\u001b[39m(\u001b[39mself\u001b[39m, overwrite \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    224\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstruct_model\n\u001b[0;32m--> 225\u001b[0m     tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39;49mBayesianOptimization(\n\u001b[1;32m    226\u001b[0m         model,\n\u001b[1;32m    227\u001b[0m         objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_categorical_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    228\u001b[0m         max_trials \u001b[39m=\u001b[39;49m \u001b[39m12\u001b[39;49m,\n\u001b[1;32m    229\u001b[0m         overwrite \u001b[39m=\u001b[39;49m overwrite\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m tuner\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/tuners/bayesian.py:460\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    437\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    448\u001b[0m ):\n\u001b[1;32m    449\u001b[0m     oracle \u001b[39m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    450\u001b[0m         objective\u001b[39m=\u001b[39mobjective,\n\u001b[1;32m    451\u001b[0m         max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m         allow_new_entries\u001b[39m=\u001b[39mallow_new_entries,\n\u001b[1;32m    459\u001b[0m     )\n\u001b[0;32m--> 460\u001b[0m     \u001b[39msuper\u001b[39;49m(\n\u001b[1;32m    461\u001b[0m         BayesianOptimization,\n\u001b[1;32m    462\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    463\u001b[0m     )\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    464\u001b[0m     \u001b[39mif\u001b[39;00m scipy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    466\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease install scipy before using the `BayesianOptimization`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:110\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 110\u001b[0m \u001b[39msuper\u001b[39;49m(Tuner, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    111\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[1;32m    112\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[1;32m    113\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m    114\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[1;32m    115\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    116\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[1;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:103\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m logger\n\u001b[1;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display \u001b[39m=\u001b[39m tuner_utils\u001b[39m.\u001b[39mDisplay(oracle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mand\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname()):\n\u001b[1;32m    106\u001b[0m     tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReloading Tuner from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname())\n\u001b[1;32m    108\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:135\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m scopes_once_active \u001b[39m=\u001b[39m []\n\u001b[1;32m    134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    137\u001b[0m     \u001b[39m# Update the recored scopes.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m conditions \u001b[39min\u001b[39;00m hp\u001b[39m.\u001b[39mactive_scopes:\n",
      "Cell \u001b[0;32mIn[8], line 207\u001b[0m, in \u001b[0;36mBERTmodel.construct_model\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    204\u001b[0m tfhub_handle_encoder, tfhub_handle_preprocess \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize_BERT()\n\u001b[1;32m    206\u001b[0m text_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstring, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m preprocessing_layer \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(tfhub_handle_preprocess, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpreprocessing\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    208\u001b[0m encoder_inputs \u001b[39m=\u001b[39m preprocessing_layer(text_input)\n\u001b[1;32m    209\u001b[0m encoder \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(tfhub_handle_encoder, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBERT_encoder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[1;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[1;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_training_argument \u001b[39m=\u001b[39m func_has_training_argument(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func)\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[0;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow_hub/module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    103\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload_v2(\n\u001b[1;32m    104\u001b[0m       module_path, tags\u001b[39m=\u001b[39mtags, options\u001b[39m=\u001b[39moptions)\n\u001b[1;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_v2(module_path, tags\u001b[39m=\u001b[39;49mtags)\n\u001b[1;32m    107\u001b[0m obj\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m is_hub_module_v1  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:828\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[1;32m    827\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 828\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    829\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/presidential_speeches/president/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:961\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    958\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[1;32m    959\u001b[0m                   ckpt_options, options, filters)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 961\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    962\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    966\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[1;32m    967\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on Sangers-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "train = (X_train, y_train)\n",
    "val = (X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "list_of_sentences_train, labels_train = train\n",
    "list_of_sentences_valid, labels_valid = val\n",
    "num_epochs = 35\n",
    "\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Convert the data into the format BERT expects\n",
    "input_ids_train = tokenizer.batch_encode_plus(list_of_sentences_train, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True)[\"input_ids\"]\n",
    "labels_train = ... # your labels for classification task\n",
    "input_ids_valid = tokenizer.batch_encode_plus(list_of_sentences_valid, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True)[\"input_ids\"]\n",
    "labels_valid = ... # your labels for classification task\n",
    "\n",
    "# Create TensorDatasets and DataLoaders for the train and validation data\n",
    "train_data = TensorDataset(torch.tensor(input_ids_train), torch.tensor(labels_train))\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_data = TensorDataset(torch.tensor(input_ids_valid), torch.tensor(labels_valid))\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set up the optimizer and criterion\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the best validation accuracy\n",
    "best_valid_acc = 0\n",
    "# Number of consecutive epochs without improvement to wait before stopping\n",
    "patience = 3\n",
    "# Number of consecutive epochs without improvement\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "# Fine-tune the model for a few epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for input_ids, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)[0]\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1} Loss {loss.item()}')\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for input_ids, labels in valid_dataloader:\n",
    "            logits = model(input_ids)[0]\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('president': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8f17d2ffe9f8eae93b159097d11b70d3a22f1d4fa5e86eb67a2effc3645481c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
